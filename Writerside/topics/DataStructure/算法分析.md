# 算法分析

## 一、算法分析

有关算法时间耗费分析，时间复杂度。算法空间（内存）占用，空间复杂度。

## 1.1 算法的时间复杂度分析

如何度量算法的执行时间。

事后分析法：

```java
public static void main(String [] args){
  long start = System.currentTimeMillis();
  
  int sum = 0;
  int n = 100;
  for(int i = 0;i <= n;i++){
    sum += i;
    System.out.println("sum="+sum);
  }
  
  long end = System.currentTimeMillis();
  System.out.pringln(end - start);
}
```



事前分析法：

在计算机程序编写前，依据统计方法对算法进行估算，经过总结，我们发现一个高级语言编写的程序在计算机上运行所消耗的时间取决于下列因素：

1. 算法采用的策略和方案‘
2. 编译产生的代码质量
3. 问题的输入规模
4. 机器执行指令的速度

由此可见，抛开这些计算机硬件，软件有关的因素，一个程序的运行时间依赖于算法的好坏和问题的输入规模。如果算法固定，那么该算法的执行时间就之和问题的输入规模有关系了。

**需求1：**

计算1~100的和。

第一种解法：

```java
public static void main(String [] args){
  int sum = 0;
  int n = 100;
  for(int i = 0;i <= n;i++){  //执行了n+1次
    sum += i;  //执行了n次
    System.out.println("sum="+sum);
  }
}
```

第二种解法：

```java
public static void main(String [] args){
  int sum = 0;
  int n = 100;
  sum = (n+1)*n/2;  //执行一次
  System.out.println("sum="+sum);
}
```

因此，当输入规模为n时，第一种算法执行了1+1+（n+1）+ n=2n+3次，第二种算法执行了1+1+1=3次。

如果把第一种算法的for循环看做是一个整体，忽略结束条件的判断，那么这两个算法的差距就是n和1的差距。

为什么循环判断执行了n+1次，可以忽略呢？

**需求1：**

计算100个1+100个2+100个3+...100个100的结果。

代码：

```java
public static void main(String [] args){
  int sum = 0;
  int n = 100;
  for(int i = 1;i <= n;i++){  
    for(int j = 1;j <= n;j++){  
    		sum+=i;
  	}
  }
  System.out.println("sum="+sum);
}
```

上面的例子中，我们要精确的研究条件执行了多少次是一件很麻烦的事情，并且，由于真正的计算和的代码是内循环的循环体，所以在研究算法的效率时，我们只考虑核心代码的执行次数，这样可以简化分析。

我们研究算法复杂度，侧重的是当输入规模不断增大时，算法的增长量是一个抽象（规律），而不是精确的定位需要执行多少次，因为如果是这样的话，我们又得考虑回编译器优化等问题，容易主次颠倒。

我们分析一个算法的运行时间，最重要的是把核心操作的次数和输入规模关联起来。



